{
    "training": {
      "per_device_train_batch_size": 1,
      "gradient_accumulation_steps": 4,
      "warmup_steps": 2,
      "max_steps": 150,
      "learning_rate": 0.0002,
      "fp16": true,
      "logging_steps": 1,
      "output_dir": "outputs",
      "optim": "paged_adamw_8bit"
    },
    "lora": {
      "r": 8,
      "target_modules": ["q_proj", "o_proj", "k_proj", "v_proj", "gate_proj", "up_proj", "down_proj"],
      "task_type": "CAUSAL_LM"
    }
  }
  