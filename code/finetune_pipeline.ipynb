{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"GL74eqFikGpX","outputId":"0a959305-d722-4afc-d1c9-a9faf5434487","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711909028479,"user_tz":240,"elapsed":68455,"user":{"displayName":"Valeria Vera Lagos","userId":"03700786808723630376"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: calflops in /usr/local/lib/python3.10/dist-packages (0.2.9)\n","Requirement already satisfied: accelerate>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from calflops) (0.27.1)\n","Requirement already satisfied: huggingface-hub>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from calflops) (0.20.3)\n","Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from calflops) (2.2.1+cu121)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.22.0->calflops) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.22.0->calflops) (24.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.22.0->calflops) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.22.0->calflops) (6.0.1)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.22.0->calflops) (0.4.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.16.4->calflops) (3.13.3)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.16.4->calflops) (2023.6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.16.4->calflops) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.16.4->calflops) (4.66.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.16.4->calflops) (4.10.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->calflops) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->calflops) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->calflops) (3.1.3)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->calflops) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->calflops) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->calflops) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->calflops) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->calflops) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->calflops) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->calflops) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->calflops) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->calflops) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->calflops) (2.19.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->calflops) (12.1.105)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->calflops) (2.2.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.1.0->calflops) (12.4.99)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.1.0->calflops) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.16.4->calflops) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.16.4->calflops) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.16.4->calflops) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.16.4->calflops) (2024.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.1.0->calflops) (1.3.0)\n"]}],"source":["!pip3 install -q -U bitsandbytes==0.42.0\n","!pip3 install -q -U peft==0.8.2\n","!pip3 install -q -U trl==0.7.10\n","!pip3 install -q -U accelerate==0.27.1\n","!pip3 install -q -U datasets==2.17.0\n","!pip3 install -q -U transformers==4.38.0\n","!pip3 install calflops"]},{"cell_type":"markdown","source":["### Pipeline and classes set up, no need to modify while doing experiments"],"metadata":{"id":"vXMh4v_j-sre"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"BG4BGhWckGpa","executionInfo":{"status":"ok","timestamp":1711909053624,"user_tz":240,"elapsed":25151,"user":{"displayName":"Valeria Vera Lagos","userId":"03700786808723630376"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"455c2b59-4dd8-463e-e243-1a84927d4019"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# Setting up packages\n","import os\n","import torch\n","import transformers\n","import logging\n","import json\n","from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, GemmaTokenizer\n","from datasets import load_dataset\n","from peft import LoraConfig\n","from trl import SFTTrainer\n","from google.colab import userdata\n","from google.colab import drive\n","from datetime import datetime\n","from datetime import timezone\n","drive.mount('/content/drive')\n","\n","# Huggingface token\n","os.environ[\"HF_TOKEN\"] = userdata.get('HF_TOKEN')\n","\n","# Setup device\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Setup logging\n","time_stamp = datetime.now(timezone.utc).strftime(\"%Y-%m-%d %H:%M:%S\")\n","file_id = f'log_{time_stamp}.txt'\n","logging.basicConfig(format='%(asctime)s %(message)s',\n","                     datefmt='%m/%d/%Y %I:%M:%S %p',\n","                     filename=file_id,\n","                     level=logging.INFO,\n","                    force=True)\n","logger = logging.getLogger(__name__)"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"7oHPbtAXkGpb","executionInfo":{"status":"ok","timestamp":1711909053625,"user_tz":240,"elapsed":19,"user":{"displayName":"Valeria Vera Lagos","userId":"03700786808723630376"}}},"outputs":[],"source":["class LargeLanguageModel():\n","    def __init__(self,model_id,bnb_config = False):\n","        self.model_id = model_id\n","\n","        # hyperparameters\n","        with open('/content/drive/MyDrive/LLMs/code/params.json', 'r') as file:\n","            params = json.load(file)\n","        self.train_params =params[\"training\"]\n","        lora_params =params[\"lora\"]\n","        self.token = os.environ['HF_TOKEN']\n","        self.bnb_config = bnb_config\n","\n","        # Model object\n","        self.model = AutoModelForCausalLM.from_pretrained(self.model_id,\n","                                             quantization_config=self.bnb_config,\n","                                             device_map={\"\":0},\n","                                             token=self.token)\n","        # Tokenizer object\n","        self.tokenizer = AutoTokenizer.from_pretrained(model_id, token=self.token)\n","\n","        # Lora object\n","        self.lora_config = LoraConfig(\n","                                    r=lora_params[\"r\"],\n","                                    target_modules=lora_params[\"target_modules\"],\n","                                    task_type=lora_params[\"task_type\"],\n","                                )\n","\n","        logging.info(f\"LLM class instantiated for model: {model_id}\")\n","        logging.info(f\"Hyperparameters: \\n{params}\")\n","\n","\n","    def generate_example(self,text):\n","        inputs = self.tokenizer(text, return_tensors=\"pt\").to(device)\n","        outputs = self.model.generate(**inputs, max_new_tokens=50)\n","        return self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n","\n","    def formatting_func(self,example):\n","        text = f\"<start_of_turn>user\\n{example['instruction'][0]}<end_of_turn> <start_of_turn>model\\n{example['response'][0]}<end_of_turn>\"\n","        return [text]\n","\n","    def finetune(self,dataset):\n","        logging.info(\"Finetuning started\")\n","        trainer = SFTTrainer(\n","            model = self.model,\n","            train_dataset = dataset.data[\"train\"],\n","            args=transformers.TrainingArguments(\n","                per_device_train_batch_size = self.train_params[\"per_device_train_batch_size\"],\n","                gradient_accumulation_steps = self.train_params[\"gradient_accumulation_steps\"],\n","                warmup_steps = self.train_params[\"warmup_steps\"],\n","                max_steps = self.train_params[\"max_steps\"],\n","                learning_rate = self.train_params[\"learning_rate\"],\n","                fp16 = self.train_params[\"fp16\"],\n","                logging_steps = self.train_params[\"logging_steps\"],\n","                output_dir = self.train_params[\"output_dir\"],\n","                optim = self.train_params[\"optim\"]\n","            ),\n","            peft_config = self.lora_config,\n","            formatting_func = self.formatting_func,\n","        )\n","\n","        trainer.train()\n","\n","        logging.info(\"Finetuning completed\")\n","        logging.info('Allocated memory:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n","        logging.info('Cached memory:', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')\n","        logging.info(\"Trainer log:\\n\",trainer.state.log_history)\n","\n","\n","class Dataset():\n","    def __init__(self):\n","        self.data = None\n","\n","    def load_data(self, dataset_id):\n","        logging.info(f\"Loading dataset: {dataset_id}\")\n","        self.data = load_dataset(dataset_id)\n","        logging.info(\"Loading dataset completed\")\n","        logging.info('Allocated memory:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n","        logging.info('Cached memory:', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')\n","\n","\n","    def print_dataset_values(self):\n","        print(self.data['train'])"]},{"cell_type":"markdown","source":["### Running experiments, modify model name, dataset. Modify hiperparams from json"],"metadata":{"id":"wKRxyd-s-0jL"}},{"cell_type":"code","execution_count":4,"metadata":{"id":"fePAWbrQkGpc","executionInfo":{"status":"ok","timestamp":1711909091132,"user_tz":240,"elapsed":37525,"user":{"displayName":"Valeria Vera Lagos","userId":"03700786808723630376"}},"outputId":"3dfe9241-b020-40a3-eee1-fd23bc52d0ac","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["da44615786ae4228957bc05af2c94e77","1c92ce12d48e4054bc1a55ea71ef37f9","4917ef30a3e44fc4bfc7f893ad073fa5","a59983087ab343e9915f2c49ca79c600","eeddc9c07f784cbbbba0a1e4fe9a4be0","3ecb3dc106f94f478a6d52b9ee259a99","5f7f03eb43fe456a9956bba5bd81f1eb","c6a71ce29f064ad785025d4740617387","9f065d013c7d462bbec53f48886ca125","c5f8fab7c6a443d28cb0fbc419fbcdad","add21973513a49b1b278d018fbc6825b"]}},"outputs":[{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da44615786ae4228957bc05af2c94e77"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Dataset({\n","    features: ['instruction', 'context', 'response', 'category'],\n","    num_rows: 15011\n","})\n"]},{"output_type":"stream","name":"stderr","text":["--- Logging error ---\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 1100, in emit\n","    msg = self.format(record)\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 943, in format\n","    return fmt.format(record)\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 678, in format\n","    record.message = record.getMessage()\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 368, in getMessage\n","    msg = msg % self.args\n","TypeError: not all arguments converted during string formatting\n","Call stack:\n","  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n","    return _run_code(code, main_globals, None,\n","  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n","    exec(code, run_globals)\n","  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n","    ColabKernelApp.launch_instance()\n","  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n","    app.start()\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n","    self.io_loop.start()\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n","    self.asyncio_loop.run_forever()\n","  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n","    self._run_once()\n","  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n","    handle._run()\n","  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n","    self._context.run(self._callback, *self._args)\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n","    lambda f: self._run_callback(functools.partial(callback, future))\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n","    ret = callback()\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n","    self.ctx_run(self.run)\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n","    yielded = self.gen.send(value)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 377, in dispatch_queue\n","    yield self.process_one()\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 250, in wrapper\n","    runner = Runner(ctx_run, result, future, yielded)\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 748, in __init__\n","    self.ctx_run(self.run)\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n","    yielded = self.gen.send(value)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n","    yield gen.maybe_future(dispatch(*args))\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n","    yielded = ctx_run(next, result)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n","    yield gen.maybe_future(handler(stream, idents, msg))\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n","    yielded = ctx_run(next, result)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n","    self.do_execute(\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n","    yielded = ctx_run(next, result)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n","    res = shell.run_cell(code, store_history=store_history, silent=silent)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n","    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n","    result = self._run_cell(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n","    return runner(coro)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n","    coro.send(None)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n","    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n","    if (await self.run_code(code, result,  async_=asy)):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-4-6ebc13f4bc95>\", line 15, in <cell line: 15>\n","    dataset.load_data(dataset_id)\n","  File \"<ipython-input-3-612e5c7c591b>\", line 75, in load_data\n","    logging.info('Allocated memory:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n","Message: 'Allocated memory:'\n","Arguments: (2.5, 'GB')\n","/usr/local/lib/python3.10/dist-packages/torch/cuda/memory.py:440: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n","  warnings.warn(\n","--- Logging error ---\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 1100, in emit\n","    msg = self.format(record)\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 943, in format\n","    return fmt.format(record)\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 678, in format\n","    record.message = record.getMessage()\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 368, in getMessage\n","    msg = msg % self.args\n","TypeError: not all arguments converted during string formatting\n","Call stack:\n","  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n","    return _run_code(code, main_globals, None,\n","  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n","    exec(code, run_globals)\n","  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n","    ColabKernelApp.launch_instance()\n","  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n","    app.start()\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n","    self.io_loop.start()\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n","    self.asyncio_loop.run_forever()\n","  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n","    self._run_once()\n","  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n","    handle._run()\n","  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n","    self._context.run(self._callback, *self._args)\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n","    lambda f: self._run_callback(functools.partial(callback, future))\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n","    ret = callback()\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n","    self.ctx_run(self.run)\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n","    yielded = self.gen.send(value)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 377, in dispatch_queue\n","    yield self.process_one()\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 250, in wrapper\n","    runner = Runner(ctx_run, result, future, yielded)\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 748, in __init__\n","    self.ctx_run(self.run)\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n","    yielded = self.gen.send(value)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n","    yield gen.maybe_future(dispatch(*args))\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n","    yielded = ctx_run(next, result)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n","    yield gen.maybe_future(handler(stream, idents, msg))\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n","    yielded = ctx_run(next, result)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n","    self.do_execute(\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n","    yielded = ctx_run(next, result)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n","    res = shell.run_cell(code, store_history=store_history, silent=silent)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n","    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n","    result = self._run_cell(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n","    return runner(coro)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n","    coro.send(None)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n","    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n","    if (await self.run_code(code, result,  async_=asy)):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-4-6ebc13f4bc95>\", line 15, in <cell line: 15>\n","    dataset.load_data(dataset_id)\n","  File \"<ipython-input-3-612e5c7c591b>\", line 76, in load_data\n","    logging.info('Cached memory:', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')\n","Message: 'Cached memory:'\n","Arguments: (2.5, 'GB')\n"]}],"source":["# Defining model and dataset\n","model_id = \"google/gemma-2b\"\n","dataset_id = \"databricks/databricks-dolly-15k\"\n","\n","# Setting up Quantization\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=torch.bfloat16\n",")\n","\n","# Generating objects\n","llm = LargeLanguageModel(model_id, bnb_config)\n","dataset = Dataset()\n","dataset.load_data(dataset_id)\n","dataset.print_dataset_values()"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"ZY8Rg9MQkGpd","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["887b07e94e324110baac35e69cbeca19","bdcbd602bf7f4992be07f8796b317665","e212a61d02b14fde9295cd08b5c166a4","f8d9d129c24846ed872b0183bcf255d3","a9be2c6072944e27a3f96da31043c48d","3c2a09b0e64046e8aa1e92fe9ef8ba0c","f2335aab8db440e9827d628391c35dc5","752a5ca5073544bc8225a48bd9b5801d","ab0ebef6e2a94ad8820b2e865fb74b15","6c69b9c8226d41d0ac8c741f6637cbd8","a654f7a8a4414db3bc6eeee265b7b192"]},"executionInfo":{"status":"ok","timestamp":1711909337545,"user_tz":240,"elapsed":246416,"user":{"displayName":"Valeria Vera Lagos","userId":"03700786808723630376"}},"outputId":"b488bb88-c0a7-4fd1-c668-10d55a4b6879"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:223: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/15011 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"887b07e94e324110baac35e69cbeca19"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:290: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [150/150 03:30, Epoch 37/38]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>2.437600</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>2.439100</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>2.157800</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>2.492400</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>2.147400</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>2.137300</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>1.921400</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>1.973100</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>1.761700</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>1.758400</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>1.523800</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>1.526600</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>1.468500</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>1.242500</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>1.304700</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>1.356400</td>\n","    </tr>\n","    <tr>\n","      <td>17</td>\n","      <td>1.235100</td>\n","    </tr>\n","    <tr>\n","      <td>18</td>\n","      <td>1.359600</td>\n","    </tr>\n","    <tr>\n","      <td>19</td>\n","      <td>1.073500</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>1.259200</td>\n","    </tr>\n","    <tr>\n","      <td>21</td>\n","      <td>1.081900</td>\n","    </tr>\n","    <tr>\n","      <td>22</td>\n","      <td>1.230000</td>\n","    </tr>\n","    <tr>\n","      <td>23</td>\n","      <td>1.057300</td>\n","    </tr>\n","    <tr>\n","      <td>24</td>\n","      <td>1.127300</td>\n","    </tr>\n","    <tr>\n","      <td>25</td>\n","      <td>1.022600</td>\n","    </tr>\n","    <tr>\n","      <td>26</td>\n","      <td>1.098400</td>\n","    </tr>\n","    <tr>\n","      <td>27</td>\n","      <td>1.102000</td>\n","    </tr>\n","    <tr>\n","      <td>28</td>\n","      <td>0.771600</td>\n","    </tr>\n","    <tr>\n","      <td>29</td>\n","      <td>0.927200</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.904200</td>\n","    </tr>\n","    <tr>\n","      <td>31</td>\n","      <td>0.795700</td>\n","    </tr>\n","    <tr>\n","      <td>32</td>\n","      <td>0.894400</td>\n","    </tr>\n","    <tr>\n","      <td>33</td>\n","      <td>0.898700</td>\n","    </tr>\n","    <tr>\n","      <td>34</td>\n","      <td>0.390800</td>\n","    </tr>\n","    <tr>\n","      <td>35</td>\n","      <td>0.883100</td>\n","    </tr>\n","    <tr>\n","      <td>36</td>\n","      <td>0.731000</td>\n","    </tr>\n","    <tr>\n","      <td>37</td>\n","      <td>0.456600</td>\n","    </tr>\n","    <tr>\n","      <td>38</td>\n","      <td>0.660900</td>\n","    </tr>\n","    <tr>\n","      <td>39</td>\n","      <td>0.642200</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.604600</td>\n","    </tr>\n","    <tr>\n","      <td>41</td>\n","      <td>0.465600</td>\n","    </tr>\n","    <tr>\n","      <td>42</td>\n","      <td>0.496200</td>\n","    </tr>\n","    <tr>\n","      <td>43</td>\n","      <td>0.388200</td>\n","    </tr>\n","    <tr>\n","      <td>44</td>\n","      <td>0.533700</td>\n","    </tr>\n","    <tr>\n","      <td>45</td>\n","      <td>0.470600</td>\n","    </tr>\n","    <tr>\n","      <td>46</td>\n","      <td>0.121200</td>\n","    </tr>\n","    <tr>\n","      <td>47</td>\n","      <td>0.241300</td>\n","    </tr>\n","    <tr>\n","      <td>48</td>\n","      <td>0.624800</td>\n","    </tr>\n","    <tr>\n","      <td>49</td>\n","      <td>0.292300</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.258100</td>\n","    </tr>\n","    <tr>\n","      <td>51</td>\n","      <td>0.290000</td>\n","    </tr>\n","    <tr>\n","      <td>52</td>\n","      <td>0.280300</td>\n","    </tr>\n","    <tr>\n","      <td>53</td>\n","      <td>0.183500</td>\n","    </tr>\n","    <tr>\n","      <td>54</td>\n","      <td>0.287200</td>\n","    </tr>\n","    <tr>\n","      <td>55</td>\n","      <td>0.314300</td>\n","    </tr>\n","    <tr>\n","      <td>56</td>\n","      <td>0.130600</td>\n","    </tr>\n","    <tr>\n","      <td>57</td>\n","      <td>0.108500</td>\n","    </tr>\n","    <tr>\n","      <td>58</td>\n","      <td>0.212800</td>\n","    </tr>\n","    <tr>\n","      <td>59</td>\n","      <td>0.070600</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.256300</td>\n","    </tr>\n","    <tr>\n","      <td>61</td>\n","      <td>0.183800</td>\n","    </tr>\n","    <tr>\n","      <td>62</td>\n","      <td>0.199100</td>\n","    </tr>\n","    <tr>\n","      <td>63</td>\n","      <td>0.067000</td>\n","    </tr>\n","    <tr>\n","      <td>64</td>\n","      <td>0.101600</td>\n","    </tr>\n","    <tr>\n","      <td>65</td>\n","      <td>0.147900</td>\n","    </tr>\n","    <tr>\n","      <td>66</td>\n","      <td>0.167300</td>\n","    </tr>\n","    <tr>\n","      <td>67</td>\n","      <td>0.059200</td>\n","    </tr>\n","    <tr>\n","      <td>68</td>\n","      <td>0.049200</td>\n","    </tr>\n","    <tr>\n","      <td>69</td>\n","      <td>0.208100</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.053300</td>\n","    </tr>\n","    <tr>\n","      <td>71</td>\n","      <td>0.046300</td>\n","    </tr>\n","    <tr>\n","      <td>72</td>\n","      <td>0.043300</td>\n","    </tr>\n","    <tr>\n","      <td>73</td>\n","      <td>0.045700</td>\n","    </tr>\n","    <tr>\n","      <td>74</td>\n","      <td>0.041400</td>\n","    </tr>\n","    <tr>\n","      <td>75</td>\n","      <td>0.095600</td>\n","    </tr>\n","    <tr>\n","      <td>76</td>\n","      <td>0.096900</td>\n","    </tr>\n","    <tr>\n","      <td>77</td>\n","      <td>0.081900</td>\n","    </tr>\n","    <tr>\n","      <td>78</td>\n","      <td>0.092500</td>\n","    </tr>\n","    <tr>\n","      <td>79</td>\n","      <td>0.039800</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.049500</td>\n","    </tr>\n","    <tr>\n","      <td>81</td>\n","      <td>0.072200</td>\n","    </tr>\n","    <tr>\n","      <td>82</td>\n","      <td>0.075200</td>\n","    </tr>\n","    <tr>\n","      <td>83</td>\n","      <td>0.041000</td>\n","    </tr>\n","    <tr>\n","      <td>84</td>\n","      <td>0.034200</td>\n","    </tr>\n","    <tr>\n","      <td>85</td>\n","      <td>0.033900</td>\n","    </tr>\n","    <tr>\n","      <td>86</td>\n","      <td>0.043000</td>\n","    </tr>\n","    <tr>\n","      <td>87</td>\n","      <td>0.073600</td>\n","    </tr>\n","    <tr>\n","      <td>88</td>\n","      <td>0.041000</td>\n","    </tr>\n","    <tr>\n","      <td>89</td>\n","      <td>0.039600</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.031000</td>\n","    </tr>\n","    <tr>\n","      <td>91</td>\n","      <td>0.053900</td>\n","    </tr>\n","    <tr>\n","      <td>92</td>\n","      <td>0.055300</td>\n","    </tr>\n","    <tr>\n","      <td>93</td>\n","      <td>0.032700</td>\n","    </tr>\n","    <tr>\n","      <td>94</td>\n","      <td>0.040100</td>\n","    </tr>\n","    <tr>\n","      <td>95</td>\n","      <td>0.050600</td>\n","    </tr>\n","    <tr>\n","      <td>96</td>\n","      <td>0.045900</td>\n","    </tr>\n","    <tr>\n","      <td>97</td>\n","      <td>0.034900</td>\n","    </tr>\n","    <tr>\n","      <td>98</td>\n","      <td>0.039400</td>\n","    </tr>\n","    <tr>\n","      <td>99</td>\n","      <td>0.049500</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.040900</td>\n","    </tr>\n","    <tr>\n","      <td>101</td>\n","      <td>0.031000</td>\n","    </tr>\n","    <tr>\n","      <td>102</td>\n","      <td>0.041000</td>\n","    </tr>\n","    <tr>\n","      <td>103</td>\n","      <td>0.041500</td>\n","    </tr>\n","    <tr>\n","      <td>104</td>\n","      <td>0.040800</td>\n","    </tr>\n","    <tr>\n","      <td>105</td>\n","      <td>0.038200</td>\n","    </tr>\n","    <tr>\n","      <td>106</td>\n","      <td>0.035000</td>\n","    </tr>\n","    <tr>\n","      <td>107</td>\n","      <td>0.042700</td>\n","    </tr>\n","    <tr>\n","      <td>108</td>\n","      <td>0.036200</td>\n","    </tr>\n","    <tr>\n","      <td>109</td>\n","      <td>0.038300</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.036900</td>\n","    </tr>\n","    <tr>\n","      <td>111</td>\n","      <td>0.031700</td>\n","    </tr>\n","    <tr>\n","      <td>112</td>\n","      <td>0.045200</td>\n","    </tr>\n","    <tr>\n","      <td>113</td>\n","      <td>0.034200</td>\n","    </tr>\n","    <tr>\n","      <td>114</td>\n","      <td>0.037100</td>\n","    </tr>\n","    <tr>\n","      <td>115</td>\n","      <td>0.038000</td>\n","    </tr>\n","    <tr>\n","      <td>116</td>\n","      <td>0.037100</td>\n","    </tr>\n","    <tr>\n","      <td>117</td>\n","      <td>0.038700</td>\n","    </tr>\n","    <tr>\n","      <td>118</td>\n","      <td>0.035100</td>\n","    </tr>\n","    <tr>\n","      <td>119</td>\n","      <td>0.035800</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.038300</td>\n","    </tr>\n","    <tr>\n","      <td>121</td>\n","      <td>0.033100</td>\n","    </tr>\n","    <tr>\n","      <td>122</td>\n","      <td>0.034900</td>\n","    </tr>\n","    <tr>\n","      <td>123</td>\n","      <td>0.039500</td>\n","    </tr>\n","    <tr>\n","      <td>124</td>\n","      <td>0.038000</td>\n","    </tr>\n","    <tr>\n","      <td>125</td>\n","      <td>0.037000</td>\n","    </tr>\n","    <tr>\n","      <td>126</td>\n","      <td>0.039300</td>\n","    </tr>\n","    <tr>\n","      <td>127</td>\n","      <td>0.033100</td>\n","    </tr>\n","    <tr>\n","      <td>128</td>\n","      <td>0.033400</td>\n","    </tr>\n","    <tr>\n","      <td>129</td>\n","      <td>0.030500</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.037400</td>\n","    </tr>\n","    <tr>\n","      <td>131</td>\n","      <td>0.032400</td>\n","    </tr>\n","    <tr>\n","      <td>132</td>\n","      <td>0.043000</td>\n","    </tr>\n","    <tr>\n","      <td>133</td>\n","      <td>0.032400</td>\n","    </tr>\n","    <tr>\n","      <td>134</td>\n","      <td>0.038300</td>\n","    </tr>\n","    <tr>\n","      <td>135</td>\n","      <td>0.034800</td>\n","    </tr>\n","    <tr>\n","      <td>136</td>\n","      <td>0.035300</td>\n","    </tr>\n","    <tr>\n","      <td>137</td>\n","      <td>0.032600</td>\n","    </tr>\n","    <tr>\n","      <td>138</td>\n","      <td>0.036500</td>\n","    </tr>\n","    <tr>\n","      <td>139</td>\n","      <td>0.030900</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.039100</td>\n","    </tr>\n","    <tr>\n","      <td>141</td>\n","      <td>0.034300</td>\n","    </tr>\n","    <tr>\n","      <td>142</td>\n","      <td>0.034700</td>\n","    </tr>\n","    <tr>\n","      <td>143</td>\n","      <td>0.034600</td>\n","    </tr>\n","    <tr>\n","      <td>144</td>\n","      <td>0.034200</td>\n","    </tr>\n","    <tr>\n","      <td>145</td>\n","      <td>0.034400</td>\n","    </tr>\n","    <tr>\n","      <td>146</td>\n","      <td>0.035400</td>\n","    </tr>\n","    <tr>\n","      <td>147</td>\n","      <td>0.032900</td>\n","    </tr>\n","    <tr>\n","      <td>148</td>\n","      <td>0.034200</td>\n","    </tr>\n","    <tr>\n","      <td>149</td>\n","      <td>0.033200</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.034500</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["--- Logging error ---\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 1100, in emit\n","    msg = self.format(record)\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 943, in format\n","    return fmt.format(record)\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 678, in format\n","    record.message = record.getMessage()\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 368, in getMessage\n","    msg = msg % self.args\n","TypeError: not all arguments converted during string formatting\n","Call stack:\n","  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n","    return _run_code(code, main_globals, None,\n","  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n","    exec(code, run_globals)\n","  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n","    ColabKernelApp.launch_instance()\n","  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n","    app.start()\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n","    self.io_loop.start()\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n","    self.asyncio_loop.run_forever()\n","  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n","    self._run_once()\n","  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n","    handle._run()\n","  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n","    self._context.run(self._callback, *self._args)\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n","    lambda f: self._run_callback(functools.partial(callback, future))\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n","    ret = callback()\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n","    self.ctx_run(self.run)\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n","    yielded = self.gen.send(value)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 377, in dispatch_queue\n","    yield self.process_one()\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 250, in wrapper\n","    runner = Runner(ctx_run, result, future, yielded)\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 748, in __init__\n","    self.ctx_run(self.run)\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n","    yielded = self.gen.send(value)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n","    yield gen.maybe_future(dispatch(*args))\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n","    yielded = ctx_run(next, result)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n","    yield gen.maybe_future(handler(stream, idents, msg))\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n","    yielded = ctx_run(next, result)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n","    self.do_execute(\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n","    yielded = ctx_run(next, result)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n","    res = shell.run_cell(code, store_history=store_history, silent=silent)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n","    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n","    result = self._run_cell(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n","    return runner(coro)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n","    coro.send(None)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n","    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n","    if (await self.run_code(code, result,  async_=asy)):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-5-d0a6b760fd77>\", line 2, in <cell line: 2>\n","    llm.finetune(dataset)\n","  File \"<ipython-input-3-612e5c7c591b>\", line 62, in finetune\n","    logging.info('Allocated memory:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n","Message: 'Allocated memory:'\n","Arguments: (3.5, 'GB')\n","--- Logging error ---\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 1100, in emit\n","    msg = self.format(record)\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 943, in format\n","    return fmt.format(record)\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 678, in format\n","    record.message = record.getMessage()\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 368, in getMessage\n","    msg = msg % self.args\n","TypeError: not all arguments converted during string formatting\n","Call stack:\n","  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n","    return _run_code(code, main_globals, None,\n","  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n","    exec(code, run_globals)\n","  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n","    ColabKernelApp.launch_instance()\n","  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n","    app.start()\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n","    self.io_loop.start()\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n","    self.asyncio_loop.run_forever()\n","  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n","    self._run_once()\n","  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n","    handle._run()\n","  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n","    self._context.run(self._callback, *self._args)\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n","    lambda f: self._run_callback(functools.partial(callback, future))\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n","    ret = callback()\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n","    self.ctx_run(self.run)\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n","    yielded = self.gen.send(value)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 377, in dispatch_queue\n","    yield self.process_one()\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 250, in wrapper\n","    runner = Runner(ctx_run, result, future, yielded)\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 748, in __init__\n","    self.ctx_run(self.run)\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n","    yielded = self.gen.send(value)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n","    yield gen.maybe_future(dispatch(*args))\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n","    yielded = ctx_run(next, result)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n","    yield gen.maybe_future(handler(stream, idents, msg))\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n","    yielded = ctx_run(next, result)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n","    self.do_execute(\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n","    yielded = ctx_run(next, result)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n","    res = shell.run_cell(code, store_history=store_history, silent=silent)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n","    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n","    result = self._run_cell(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n","    return runner(coro)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n","    coro.send(None)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n","    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n","    if (await self.run_code(code, result,  async_=asy)):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-5-d0a6b760fd77>\", line 2, in <cell line: 2>\n","    llm.finetune(dataset)\n","  File \"<ipython-input-3-612e5c7c591b>\", line 63, in finetune\n","    logging.info('Cached memory:', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')\n","Message: 'Cached memory:'\n","Arguments: (7.1, 'GB')\n"]}],"source":["# Finetuning\n","llm.finetune(dataset)\n","\n","# Save log\n","cp log* \"/content/drive/MyDrive/LLMs/code/logs/\""]},{"cell_type":"code","source":["text = \"\"\"<start_of_turn>user\n","Can you explain how to use WNetAddConnection to map a network share?<end_of_turn>\n","<start_of_turn>model\"\"\"\n","llm.generate_example(text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"YX7v8ZfD79YH","executionInfo":{"status":"ok","timestamp":1711909342946,"user_tz":240,"elapsed":5409,"user":{"displayName":"Valeria Vera Lagos","userId":"03700786808723630376"}},"outputId":"748ec321-078b-43a9-ccce-9dc046f40e5d"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"<start_of_turn>user\\nCan you explain how to use WNetAddConnection to map a network share?<end_of_turn>\\n<start_of_turn>model\\nWNetAddConnection is a Windows API that allows you to map a network share to a drive letter. Here's how you would use it:\\n\\n1. Import the WNetAddConnectionW API into your program.\\n2. Call\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":8}]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"colab":{"provenance":[{"file_id":"https://github.com/valeriavla/llm_finetuning_helm/blob/main/code/finetune_pipeline.ipynb","timestamp":1711723320090}],"gpuType":"T4"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"da44615786ae4228957bc05af2c94e77":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1c92ce12d48e4054bc1a55ea71ef37f9","IPY_MODEL_4917ef30a3e44fc4bfc7f893ad073fa5","IPY_MODEL_a59983087ab343e9915f2c49ca79c600"],"layout":"IPY_MODEL_eeddc9c07f784cbbbba0a1e4fe9a4be0"}},"1c92ce12d48e4054bc1a55ea71ef37f9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3ecb3dc106f94f478a6d52b9ee259a99","placeholder":"​","style":"IPY_MODEL_5f7f03eb43fe456a9956bba5bd81f1eb","value":"Loading checkpoint shards: 100%"}},"4917ef30a3e44fc4bfc7f893ad073fa5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c6a71ce29f064ad785025d4740617387","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9f065d013c7d462bbec53f48886ca125","value":2}},"a59983087ab343e9915f2c49ca79c600":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c5f8fab7c6a443d28cb0fbc419fbcdad","placeholder":"​","style":"IPY_MODEL_add21973513a49b1b278d018fbc6825b","value":" 2/2 [00:30&lt;00:00, 12.49s/it]"}},"eeddc9c07f784cbbbba0a1e4fe9a4be0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ecb3dc106f94f478a6d52b9ee259a99":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5f7f03eb43fe456a9956bba5bd81f1eb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c6a71ce29f064ad785025d4740617387":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f065d013c7d462bbec53f48886ca125":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c5f8fab7c6a443d28cb0fbc419fbcdad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"add21973513a49b1b278d018fbc6825b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"887b07e94e324110baac35e69cbeca19":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bdcbd602bf7f4992be07f8796b317665","IPY_MODEL_e212a61d02b14fde9295cd08b5c166a4","IPY_MODEL_f8d9d129c24846ed872b0183bcf255d3"],"layout":"IPY_MODEL_a9be2c6072944e27a3f96da31043c48d"}},"bdcbd602bf7f4992be07f8796b317665":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3c2a09b0e64046e8aa1e92fe9ef8ba0c","placeholder":"​","style":"IPY_MODEL_f2335aab8db440e9827d628391c35dc5","value":"Map: 100%"}},"e212a61d02b14fde9295cd08b5c166a4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_752a5ca5073544bc8225a48bd9b5801d","max":15011,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ab0ebef6e2a94ad8820b2e865fb74b15","value":15011}},"f8d9d129c24846ed872b0183bcf255d3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6c69b9c8226d41d0ac8c741f6637cbd8","placeholder":"​","style":"IPY_MODEL_a654f7a8a4414db3bc6eeee265b7b192","value":" 15011/15011 [00:00&lt;00:00, 2028.93 examples/s]"}},"a9be2c6072944e27a3f96da31043c48d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c2a09b0e64046e8aa1e92fe9ef8ba0c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f2335aab8db440e9827d628391c35dc5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"752a5ca5073544bc8225a48bd9b5801d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab0ebef6e2a94ad8820b2e865fb74b15":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6c69b9c8226d41d0ac8c741f6637cbd8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a654f7a8a4414db3bc6eeee265b7b192":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}